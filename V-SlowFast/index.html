<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>V-SlowFast</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="icon" type="image/png" href="https://ly-zhu.github.io/images/zhu_icon.jpeg">

    <link rel="stylesheet" href="https://ly-zhu.github.io/assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://ly-zhu.github.io/assets/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://ly-zhu.github.io/assets/css/codemirror.min.css">
    <link rel="stylesheet" href="https://ly-zhu.github.io/assets/css/app.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="https://ly-zhu.github.io/assets/js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                <b> V-SlowFast Network for Efficient Visual Sound Separation</b>
                <small>
                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://ly-zhu.github.io/">
                          Lingyu Zhu
                        </a>
                        </br>Tampere University
                    </li>
                    <li>
                        <a href="https://esa.rahtu.fi/">
                          Esa Rahtu
                        </a>
                        </br>Tampere University
                    </li>
                </ul>    
            </div>
        </div>

        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Zhu_V-SlowFast_Network_for_Efficient_Visual_Sound_Separation_WACV_2022_paper.pdf">
                        <image src="figures/paper_img.png" height="120px"><br>
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <!--
                        <a href="https://github.com/ly-zhu/cof-net">
                        -->
                        <image src="https://ly-zhu.github.io/images/github_icon.png" height="120px"><br>
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:35%;">
                        <image src="figures/fig1.png" style="position:absolute;top:0;left:0;width:100%"><br>
                        <p class="text-justify">
                            The objective of this paper is to perform visual sound separation: i) we study visual sound separation on spectrograms of different temporal resolutions; ii) we propose a new light yet efficient three-stream framework V-SlowFast that operates on Visual frame, Slow spectrogram, and Fast spectrogram. The Slow spectrogram captures the coarse temporal resolution while the Fast spectrogram contains the fine-grained temporal resolution; iii) we introduce two contrastive objectives to encourage the network to learn discriminative visual features for separating sounds; iv) we propose an audio-visual global attention module for audio and visual feature fusion; v) the introduced V-SlowFast model outperforms previous state-of-the-art in single-frame based visual sound separation on small- and large-scale datasets: MUSIC-21, AVE, and VGG-Sound. We also propose a small V-SlowFast architecture variant, which achieves 74.2% reduction in the number of model parameters and 81.4% reduction in GMACs compared to the previous multi-stage models.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Architecture
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:40%;">
                        <image src="figures/overview.png" style="position:absolute;top:0;left:0;width:100%"><br>
                        <p class="text-justify">
                        The goal of the visual sound separation is to extract the component audio that corresponds to the sound source in the given visual frame. The proposed V-SlowFast network contains four components: vision network, audio-visual global attention module, slow spectrogram network, and fast spectrogram residual network. The vision network randomly extracts a single frame from the input video sequence and encodes it into a feature vector. To enhance the discrimination between semantic categories, we randomly sample an additional visual frame from a same (positive) or different (negative) category video to make contrastive pairs during the training procedure. We apply two visual contrastive objectives (embedding and localization) to the contrastive pairs along the vision network. The audio-visual global attention module fuses the visual embedding with sound features. The slow spectrogram network performs source separation at the coarse time scale (low sampling rate) using appearance features. The obtained result and the original mixture are further passed to the fast spectrogram residual network, which refines the source separation using spectrogram with higher temporal resolution (high sampling rate).
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Source separation performance in comparison with recent works (separating two sound sources)
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:30%;">
                        <image src="figures/result.png" style="position:absolute;top:0;left:0;width:100%"><br>
                        <p class="text-justify">
                            Table 1 summarizes the results in comparison with recent single frame methods Sound of Pixels , Minus-Plus and Cascaded Opponent Filter (COF) on MUSIC-21, AVE and VGGSound datasets using mixtures of two sound sources (N=2). We observe that our method consistently outperforms all baselines. Impressively, our system V-SlowFast (1) outperforms previous state-of-the-art multi-stage method by 1.39dB on MUSIC-21, 0.41dB on AVE, and 0.66dB on VGG-Sound in terms of SDR while having substantially less parameters and small computational cost.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        

        <div class="row" style="position:relative;padding-top:00%;">
            <div class="col-md-8 col-md-offset-2" >
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-15 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{zhu2022v,
    title={V-slowfast network for efficient visual sound separation},
    author={Zhu, Lingyu and Rahtu, Esa},
    booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
    pages={1464--1474},
    year={2022}
}
                </textarea>
                </div>
            </div>
        </div>

    </div>
</body>
</html>
